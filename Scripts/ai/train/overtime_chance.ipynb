{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1de56208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import os\n",
    "import joblib\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "from utils.data_handler import get_games, compute_head_to_head_avg, get_season_start\n",
    "df = get_games()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b838f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['home_avg_points'] = (\n",
    "    df.groupby('home_teamId')['home_teamScore']\n",
    "    .transform(lambda x: x.shift(1).expanding().mean())\n",
    ")\n",
    "df['away_avg_points'] = (\n",
    "    df.groupby('away_teamId')['away_teamScore']\n",
    "    .transform(lambda x: x.shift(1).expanding().mean())\n",
    ")\n",
    "\n",
    "df[['home_head_to_head_avg_points', 'away_head_to_head_avg_points']] = df.apply(\n",
    "    lambda row: compute_head_to_head_avg(row, df), axis=1\n",
    ")\n",
    "\n",
    "df['home_last_5_win_percentage'] = (\n",
    "    df.groupby('home_teamId')['home_win']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "df['away_last_5_win_percentage'] = (\n",
    "    df.groupby('away_teamId')['away_win']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "df['gameDate'] = pd.to_datetime(df['gameDate'], errors='coerce', utc=True)\n",
    "\n",
    "df['season'] = df['gameDate'].apply(get_season_start)\n",
    "\n",
    "df = df.sort_values('gameDate').reset_index(drop=True)\n",
    "\n",
    "df['home_season_win_percentage'] = (\n",
    "    df.groupby(['home_teamId', 'season'])['home_win']\n",
    "    .transform(lambda x: x.shift(1).expanding().mean())\n",
    ")\n",
    "\n",
    "df['away_season_win_percentage'] = (\n",
    "    df.groupby(['away_teamId', 'season'])['away_win']\n",
    "    .transform(lambda x: x.shift(1).expanding().mean())\n",
    ")\n",
    "\n",
    "df['home_advantage'] = 1\n",
    "\n",
    "# Offensive Efficiency (points per possession)\n",
    "df['home_possessions'] = df['home_fieldGoalsAttempted'] + 0.44 * df['home_freeThrowsAttempted'] + df['home_turnovers']\n",
    "df['away_possessions'] = df['away_fieldGoalsAttempted'] + 0.44 * df['away_freeThrowsAttempted'] + df['away_turnovers']\n",
    "\n",
    "df['home_off_efficiency'] = df['home_teamScore'] / df['home_possessions'].replace(0, np.nan)\n",
    "df['away_off_efficiency'] = df['away_teamScore'] / df['away_possessions'].replace(0, np.nan)\n",
    "\n",
    "df['home_off_eff_L5'] = (\n",
    "    df.groupby('home_teamId')['home_off_efficiency']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "df['away_off_eff_L5'] = (\n",
    "    df.groupby('away_teamId')['away_off_efficiency']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "df['home_off_eff_L10'] = (\n",
    "    df.groupby('home_teamId')['home_off_efficiency']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=10, min_periods=1).mean())\n",
    ")\n",
    "df['away_off_eff_L10'] = (\n",
    "    df.groupby('away_teamId')['away_off_efficiency']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=10, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "# Defensive Efficiency (points allowed)\n",
    "df['home_def_efficiency'] = (\n",
    "    df.groupby('home_teamId')['away_teamScore']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "df['away_def_efficiency'] = (\n",
    "    df.groupby('away_teamId')['home_teamScore']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "# Pace (possessions per game)\n",
    "df['game_pace'] = (df['home_possessions'] + df['away_possessions']) / 2\n",
    "df['home_pace_L5'] = (\n",
    "    df.groupby('home_teamId')['game_pace']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "df['away_pace_L5'] = (\n",
    "    df.groupby('away_teamId')['game_pace']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "df['home_pace'] = (\n",
    "    df['home_fieldGoalsAttempted'] + df['home_turnovers'] + 0.44 * df['home_freeThrowsAttempted']\n",
    ")\n",
    "df['away_pace'] = (\n",
    "    df['away_fieldGoalsAttempted'] + df['away_turnovers'] + 0.44 * df['away_freeThrowsAttempted']\n",
    ")\n",
    "\n",
    "df['home_pace_avg'] = (\n",
    "    df.groupby('home_teamId')['home_pace']\n",
    "    .transform(lambda x: x.shift(1).expanding().mean())\n",
    ")\n",
    "df['away_pace_avg'] = (\n",
    "    df.groupby('away_teamId')['away_pace']\n",
    "    .transform(lambda x: x.shift(1).expanding().mean())\n",
    ")\n",
    "\n",
    "df['pace_sum'] = df['home_pace_avg'] + df['away_pace_avg']\n",
    "\n",
    "df['home_eFG'] = (df['home_fieldGoalsMade'] + 0.5 * df['home_threePointersMade']) / df['home_fieldGoalsAttempted'].replace(0, np.nan)\n",
    "df['away_eFG'] = (df['away_fieldGoalsMade'] + 0.5 * df['away_threePointersMade']) / df['away_fieldGoalsAttempted'].replace(0, np.nan)\n",
    "\n",
    "df['home_eFG_L5'] = (\n",
    "    df.groupby('home_teamId')['home_eFG']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "df['away_eFG_L5'] = (\n",
    "    df.groupby('away_teamId')['away_eFG']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "df['home_eFG_L10'] = (\n",
    "    df.groupby('home_teamId')['home_eFG']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=10, min_periods=1).mean())\n",
    ")\n",
    "df['away_eFG_L10'] = (\n",
    "    df.groupby('away_teamId')['away_eFG']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=10, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "# Three-Point Shooting\n",
    "df['home_3p_made_L5'] = (\n",
    "    df.groupby('home_teamId')['home_threePointersMade']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "df['away_3p_made_L5'] = (\n",
    "    df.groupby('away_teamId')['away_threePointersMade']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "df['home_reb_L5'] = (\n",
    "    df.groupby('home_teamId')['home_reboundsTotal']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "df['away_reb_L5'] = (\n",
    "    df.groupby('away_teamId')['away_reboundsTotal']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "df['home_oreb_rate'] = df['home_reboundsOffensive'] / (df['home_reboundsOffensive'] + df['away_reboundsDefensive']).replace(0, np.nan)\n",
    "df['away_oreb_rate'] = df['away_reboundsOffensive'] / (df['away_reboundsOffensive'] + df['home_reboundsDefensive']).replace(0, np.nan)\n",
    "\n",
    "df['home_oreb_rate_L5'] = (\n",
    "    df.groupby('home_teamId')['home_oreb_rate']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "df['away_oreb_rate_L5'] = (\n",
    "    df.groupby('away_teamId')['away_oreb_rate']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "df['home_to_L5'] = (\n",
    "    df.groupby('home_teamId')['home_turnovers']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "df['away_to_L5'] = (\n",
    "    df.groupby('away_teamId')['away_turnovers']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "df['home_ast_L5'] = (\n",
    "    df.groupby('home_teamId')['home_assists']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "df['away_ast_L5'] = (\n",
    "    df.groupby('away_teamId')['away_assists']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "# Points in Paint\n",
    "df['home_paint_L5'] = (\n",
    "    df.groupby('home_teamId')['home_pointsInThePaint']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "df['away_paint_L5'] = (\n",
    "    df.groupby('away_teamId')['away_pointsInThePaint']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "df['home_fastbreak_L5'] = (\n",
    "    df.groupby('home_teamId')['home_pointsFastBreak']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "df['away_fastbreak_L5'] = (\n",
    "    df.groupby('away_teamId')['away_pointsFastBreak']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "df['home_pts_L3'] = (\n",
    "    df.groupby('home_teamId')['home_teamScore']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=3, min_periods=1).mean())\n",
    ")\n",
    "df['away_pts_L3'] = (\n",
    "    df.groupby('away_teamId')['away_teamScore']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=3, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "df['home_pts_L5'] = (\n",
    "    df.groupby('home_teamId')['home_teamScore']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "df['away_pts_L5'] = (\n",
    "    df.groupby('away_teamId')['away_teamScore']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "df['home_pts_L10'] = (\n",
    "    df.groupby('home_teamId')['home_teamScore']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=10, min_periods=1).mean())\n",
    ")\n",
    "df['away_pts_L10'] = (\n",
    "    df.groupby('away_teamId')['away_teamScore']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=10, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "df['home_pts_std_L10'] = (\n",
    "    df.groupby('home_teamId')['home_teamScore']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=10, min_periods=3).std())\n",
    ")\n",
    "df['away_pts_std_L10'] = (\n",
    "    df.groupby('away_teamId')['away_teamScore']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=10, min_periods=3).std())\n",
    ")\n",
    "\n",
    "df['home_home_pts_avg'] = (\n",
    "    df.groupby('home_teamId')['home_teamScore']\n",
    "    .transform(lambda x: x.shift(1).expanding().mean())\n",
    ")\n",
    "df['away_away_pts_avg'] = (\n",
    "    df.groupby('away_teamId')['away_teamScore']\n",
    "    .transform(lambda x: x.shift(1).expanding().mean())\n",
    ")\n",
    "\n",
    "df['home_trend_10'] = (\n",
    "    df.groupby('home_teamId')['home_teamScore']\n",
    "    .transform(lambda x: x.shift(1).rolling(10, 2).apply(lambda x: x.iloc[-1] - x.iloc[0]))\n",
    ")\n",
    "\n",
    "df['away_trend_10'] = (\n",
    "    df.groupby('away_teamId')['away_teamScore']\n",
    "    .transform(lambda x: x.shift(1).rolling(10, 2).apply(lambda x: x.iloc[-1] - x.iloc[0]))\n",
    ")\n",
    "\n",
    "df['home_allowed_avg'] = (\n",
    "    df.groupby('home_teamId')['away_teamScore']\n",
    "    .transform(lambda x: x.shift(1).expanding().mean())\n",
    ")\n",
    "df['away_allowed_avg'] = (\n",
    "    df.groupby('away_teamId')['home_teamScore']\n",
    "    .transform(lambda x: x.shift(1).expanding().mean())\n",
    ")\n",
    "\n",
    "df['home_win_pct_L10'] = (\n",
    "    df.groupby('home_teamId')['home_win']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=10, min_periods=1).mean())\n",
    ")\n",
    "df['away_win_pct_L10'] = (\n",
    "    df.groupby('away_teamId')['away_win']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=10, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "df['expected_total_score'] = df['home_pts_L10'] + df['away_pts_L10']\n",
    "df['expected_home_vs_away_def'] = df['home_off_eff_L10'] * df['away_def_efficiency']\n",
    "df['expected_away_vs_home_def'] = df['away_off_eff_L10'] * df['home_def_efficiency']\n",
    "\n",
    "df['home_off_season'] = (\n",
    "    df.groupby('home_teamId')['home_teamScore']\n",
    "    .transform(lambda x: x.shift(1).expanding().mean())\n",
    ")\n",
    "df['away_off_season'] = (\n",
    "    df.groupby('away_teamId')['away_teamScore']\n",
    "    .transform(lambda x: x.shift(1).expanding().mean())\n",
    ")\n",
    "\n",
    "df['home_def_season'] = (\n",
    "    df.groupby('home_teamId')['away_teamScore']\n",
    "    .transform(lambda x: x.shift(1).expanding().mean())\n",
    ")\n",
    "df['away_def_season'] = (\n",
    "    df.groupby('away_teamId')['home_teamScore']\n",
    "    .transform(lambda x: x.shift(1).expanding().mean())\n",
    ")\n",
    "\n",
    "df['expected_total_pre'] = (\n",
    "    0.5 * (df['home_off_season'] + df['away_off_season']) -\n",
    "    0.3 * (df['home_def_season'] + df['away_def_season']) +\n",
    "    0.1 * df['pace_sum']\n",
    ")\n",
    "\n",
    "df['pace_differential'] = df['home_pace_L5'] - df['away_pace_L5']\n",
    "\n",
    "df['off_eff_differential'] = df['home_off_eff_L10'] - df['away_off_eff_L10']\n",
    "df['def_eff_differential'] = df['home_def_efficiency'] - df['away_def_efficiency']\n",
    "\n",
    "df['eFG_differential'] = df['home_eFG_L10'] - df['away_eFG_L10']\n",
    "\n",
    "df['home_momentum'] = (\n",
    "    df.groupby('home_teamId')['home_teamScore']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=3, min_periods=2).apply(\n",
    "        lambda vals: vals.iloc[-1] - vals.iloc[0] if len(vals) >= 2 else 0\n",
    "    ))\n",
    ")\n",
    "df['away_momentum'] = (\n",
    "    df.groupby('away_teamId')['away_teamScore']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=3, min_periods=2).apply(\n",
    "        lambda vals: vals.iloc[-1] - vals.iloc[0] if len(vals) >= 2 else 0\n",
    "    ))\n",
    ")\n",
    "\n",
    "df['home_pts_weighted'] = (\n",
    "    df.groupby('home_teamId')['home_teamScore']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).apply(\n",
    "        lambda vals: np.average(vals, weights=range(1, len(vals)+1)) if len(vals) > 0 else np.nan\n",
    "    ))\n",
    ")\n",
    "df['away_pts_weighted'] = (\n",
    "    df.groupby('away_teamId')['away_teamScore']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).apply(\n",
    "        lambda vals: np.average(vals, weights=range(1, len(vals)+1)) if len(vals) > 0 else np.nan\n",
    "    ))\n",
    ")\n",
    "\n",
    "df['home_TS'] = df['home_teamScore'] / (2 * (df['home_fieldGoalsAttempted'] + 0.44 * df['home_freeThrowsAttempted'])).replace(0, np.nan)\n",
    "df['away_TS'] = df['away_teamScore'] / (2 * (df['away_fieldGoalsAttempted'] + 0.44 * df['away_freeThrowsAttempted'])).replace(0, np.nan)\n",
    "\n",
    "df['home_TS_L5'] = (\n",
    "    df.groupby('home_teamId')['home_TS']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "df['away_TS_L5'] = (\n",
    "    df.groupby('away_teamId')['away_TS']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "df['home_tov_rate'] = df['home_turnovers'] / df['home_possessions'].replace(0, np.nan)\n",
    "df['away_tov_rate'] = df['away_turnovers'] / df['away_possessions'].replace(0, np.nan)\n",
    "\n",
    "df['home_tov_rate_L5'] = (\n",
    "    df.groupby('home_teamId')['home_tov_rate']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "df['away_tov_rate_L5'] = (\n",
    "    df.groupby('away_teamId')['away_tov_rate']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "df['home_ft_rate'] = df['home_freeThrowsAttempted'] / df['home_fieldGoalsAttempted'].replace(0, np.nan)\n",
    "df['away_ft_rate'] = df['away_freeThrowsAttempted'] / df['away_fieldGoalsAttempted'].replace(0, np.nan)\n",
    "\n",
    "df['home_ft_rate_L5'] = (\n",
    "    df.groupby('home_teamId')['home_ft_rate']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "df['away_ft_rate_L5'] = (\n",
    "    df.groupby('away_teamId')['away_ft_rate']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "df['home_rest_days'] = df.groupby('home_teamId')['gameDate'].diff().dt.days\n",
    "df['away_rest_days'] = df.groupby('away_teamId')['gameDate'].diff().dt.days\n",
    "df['home_rest_days'] = df['home_rest_days'].fillna(3).clip(0, 7)  # Cap at 7 days\n",
    "df['away_rest_days'] = df['away_rest_days'].fillna(3).clip(0, 7)\n",
    "\n",
    "df['rest_diff'] = df['home_rest_days'] - df['away_rest_days']\n",
    "\n",
    "df['home_back_to_back'] = (df['home_rest_days'] <= 1).astype(int)\n",
    "df['away_back_to_back'] = (df['away_rest_days'] <= 1).astype(int)\n",
    "\n",
    "df['home_off_eff_weighted'] = (\n",
    "    df.groupby('home_teamId')['home_off_efficiency']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).apply(\n",
    "        lambda vals: np.average(vals, weights=range(1, len(vals)+1)) if len(vals) > 0 else np.nan\n",
    "    ))\n",
    ")\n",
    "df['away_off_eff_weighted'] = (\n",
    "    df.groupby('away_teamId')['away_off_efficiency']\n",
    "    .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).apply(\n",
    "        lambda vals: np.average(vals, weights=range(1, len(vals)+1)) if len(vals) > 0 else np.nan\n",
    "    ))\n",
    ")\n",
    "\n",
    "df = df.sort_values(\"gameDate\").reset_index(drop=True)\n",
    "base_elo = 1500\n",
    "k = 20\n",
    "\n",
    "elo = {}\n",
    "\n",
    "df['home_elo'] = 0.0\n",
    "df['away_elo'] = 0.0\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    h, a = row['home_teamId'], row['away_teamId']\n",
    "\n",
    "    # Initialize if unseen\n",
    "    elo.setdefault(h, base_elo)\n",
    "    elo.setdefault(a, base_elo)\n",
    "\n",
    "    # Assign ELO before game\n",
    "    df.at[i, 'home_elo'] = elo[h]\n",
    "    df.at[i, 'away_elo'] = elo[a]\n",
    "\n",
    "    # Calculate expected probabilities\n",
    "    expected_home = 1 / (1 + 10 ** ((elo[a] - elo[h]) / 400))\n",
    "\n",
    "    # Actual result\n",
    "    actual_home = 1 if row['home_win'] == 1 else 0\n",
    "\n",
    "    # Update ELO\n",
    "    elo[h] += k * (actual_home - expected_home)\n",
    "    elo[a] -= k * (actual_home - expected_home)\n",
    "\n",
    "df['elo_diff'] = df['home_elo'] - df['away_elo']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9ec0a7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.950\n",
      "AUC: 0.471\n",
      "F1 Score: 0.017\n",
      "\n",
      "Predicted overtime probability: 5.75%\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    \"home_avg_points\",\n",
    "    \"away_avg_points\",\n",
    "    \"home_head_to_head_avg_points\",\n",
    "    \"away_head_to_head_avg_points\",\n",
    "    \"home_last_5_win_percentage\",\n",
    "    \"away_last_5_win_percentage\",\n",
    "    \"home_advantage\",\n",
    "]\n",
    "\n",
    "df = df.dropna(subset=features + [\"overtime\"]).reset_index(drop=True)\n",
    "X = df[features]\n",
    "y = df[\"overtime\"].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "print(f\"AUC: {auc:.3f}\")\n",
    "print(f\"F1 Score: {f1:.3f}\")\n",
    "\n",
    "sample = X_test_scaled[:1]\n",
    "prob_ot = model.predict_proba(sample)[0, 1]\n",
    "print(f\"\\nPredicted overtime probability: {prob_ot*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "168c61ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overtime rate: 0.04989932592138668\n",
      "0:\ttest: 0.5303704\tbest: 0.5303704 (0)\ttotal: 3.02ms\tremaining: 2.42s\n",
      "200:\ttest: 0.5203480\tbest: 0.5440415 (81)\ttotal: 305ms\tremaining: 907ms\n",
      "400:\ttest: 0.5112326\tbest: 0.5440415 (81)\ttotal: 604ms\tremaining: 601ms\n",
      "600:\ttest: 0.4965090\tbest: 0.5440415 (81)\ttotal: 906ms\tremaining: 300ms\n",
      "799:\ttest: 0.5037940\tbest: 0.5440415 (81)\ttotal: 1.21s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5440414717\n",
      "bestIteration = 81\n",
      "\n",
      "Shrink model to first 82 iterations.\n",
      "\n",
      "Metrics AFTER REAL calibration:\n",
      "Accuracy: 0.9466083150984683\n",
      "AUC: 0.5440414717124455\n",
      "F1: 0.0\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "catboost/libs/data/model_dataset_compatibility.cpp:72: Feature home_off_eff_L10 is present in model but not in pool.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCatBoostError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 79\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAUC:\u001b[39m\u001b[33m\"\u001b[39m, roc_auc_score(y_test, y_prob))\n\u001b[32m     77\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mF1:\u001b[39m\u001b[33m\"\u001b[39m, f1_score(y_test, y_pred))\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m sample_raw = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRawFormulaVal\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m sample_raw = \u001b[38;5;28mfloat\u001b[39m(sample_raw)  \u001b[38;5;66;03m# convert to scalar\u001b[39;00m\n\u001b[32m     81\u001b[39m sample_prob = calibrator.predict_proba([[sample_raw]])[\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/catboost/core.py:5307\u001b[39m, in \u001b[36mCatBoostClassifier.predict\u001b[39m\u001b[34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[39m\n\u001b[32m   5250\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, prediction_type=\u001b[33m'\u001b[39m\u001b[33mClass\u001b[39m\u001b[33m'\u001b[39m, ntree_start=\u001b[32m0\u001b[39m, ntree_end=\u001b[32m0\u001b[39m, thread_count=-\u001b[32m1\u001b[39m, verbose=\u001b[38;5;28;01mNone\u001b[39;00m, task_type=\u001b[33m\"\u001b[39m\u001b[33mCPU\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   5251\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5252\u001b[39m \u001b[33;03m    Predict with data.\u001b[39;00m\n\u001b[32m   5253\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5305\u001b[39m \u001b[33;03m              with log probability for every class for each object.\u001b[39;00m\n\u001b[32m   5306\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5307\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpredict\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/catboost/core.py:2623\u001b[39m, in \u001b[36mCatBoost._predict\u001b[39m\u001b[34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, parent_method_name, task_type)\u001b[39m\n\u001b[32m   2620\u001b[39m data, data_is_single_object = \u001b[38;5;28mself\u001b[39m._process_predict_input_data(data, parent_method_name, thread_count)\n\u001b[32m   2621\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_prediction_type(prediction_type)\n\u001b[32m-> \u001b[39m\u001b[32m2623\u001b[39m predictions = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_base_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2624\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m predictions[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m data_is_single_object \u001b[38;5;28;01melse\u001b[39;00m predictions\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/catboost/core.py:1842\u001b[39m, in \u001b[36m_CatBoostBase._base_predict\u001b[39m\u001b[34m(self, pool, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[39m\n\u001b[32m   1841\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_base_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, pool, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type):\n\u001b[32m-> \u001b[39m\u001b[32m1842\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_base_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5155\u001b[39m, in \u001b[36m_catboost._CatBoost._base_predict\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5162\u001b[39m, in \u001b[36m_catboost._CatBoost._base_predict\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mCatBoostError\u001b[39m: catboost/libs/data/model_dataset_compatibility.cpp:72: Feature home_off_eff_L10 is present in model but not in pool."
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    \"elo_diff\",\n",
    "    \"home_avg_points\",\n",
    "    \"away_avg_points\",\n",
    "    \"home_last_5_win_percentage\",\n",
    "    \"away_last_5_win_percentage\",\n",
    "    \"home_season_win_percentage\",\n",
    "    \"away_season_win_percentage\",\n",
    "    \"home_off_eff_L10\",\n",
    "    \"away_off_eff_L10\",\n",
    "    \"home_def_efficiency\",\n",
    "    \"away_def_efficiency\",\n",
    "    \"home_pace_avg\",\n",
    "    \"away_pace_avg\",\n",
    "    \"pace_sum\",\n",
    "    \"home_pts_std_L10\",\n",
    "    \"away_pts_std_L10\",\n",
    "    \"expected_total_pre\",\n",
    "    \"off_eff_differential\",\n",
    "    \"def_eff_differential\",\n",
    "    \"eFG_differential\",\n",
    "    \"rest_diff\",\n",
    "    \"home_back_to_back\",\n",
    "    \"away_back_to_back\",\n",
    "]\n",
    "\n",
    "for col in features:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "df[\"overtime\"] = df[\"overtime\"].astype(int)\n",
    "\n",
    "print(\"Overtime rate:\", df[\"overtime\"].mean())\n",
    "\n",
    "X = df[features]\n",
    "y = df[\"overtime\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=800,\n",
    "    depth=6,\n",
    "    learning_rate=0.03,\n",
    "    loss_function=\"Logloss\",\n",
    "    eval_metric=\"AUC\",\n",
    "    class_weights=[1, 15],\n",
    "    random_seed=42,\n",
    "    verbose=200\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, eval_set=(X_test, y_test))\n",
    "\n",
    "train_raw = model.predict(X_train, prediction_type=\"RawFormulaVal\")\n",
    "test_raw  = model.predict(X_test,  prediction_type=\"RawFormulaVal\")\n",
    "\n",
    "import numpy as np\n",
    "train_raw = np.array(train_raw).reshape(-1, 1)\n",
    "test_raw  = np.array(test_raw).reshape(-1, 1)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "calibrator = LogisticRegression(max_iter=500)\n",
    "calibrator.fit(train_raw, y_train)\n",
    "\n",
    "y_prob = calibrator.predict_proba(test_raw)[:, 1]\n",
    "y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "\n",
    "print(\"\\nMetrics AFTER REAL calibration:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_prob))\n",
    "print(\"F1:\", f1_score(y_test, y_pred))\n",
    "\n",
    "sample_raw = model.predict(sample, prediction_type=\"RawFormulaVal\")\n",
    "sample_raw = float(sample_raw)  # convert to scalar\n",
    "sample_prob = calibrator.predict_proba([[sample_raw]])[0, 1]\n",
    "\n",
    "print(f\"\\nCalibrated OT probability: {sample_prob * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d9344a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     gameId  skellam_ot_prob\n",
      "0  12500008         0.024441\n",
      "1  12500001         0.026853\n",
      "2  12500010         0.026025\n",
      "3  12500027         0.026158\n",
      "4  12500028         0.025917\n",
      "\n",
      "Predicted Skellam OT probability: 2.55%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.stats import skellam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "score_features = [\n",
    "    \"elo_diff\",\n",
    "    \"home_avg_points\",\n",
    "    \"away_avg_points\",\n",
    "    \"home_last_5_win_percentage\",\n",
    "    \"away_last_5_win_percentage\",\n",
    "    \"home_season_win_percentage\",\n",
    "    \"away_season_win_percentage\",\n",
    "    \"home_off_eff_L10\",\n",
    "    \"away_off_eff_L10\",\n",
    "    \"home_def_efficiency\",\n",
    "    \"away_def_efficiency\",\n",
    "    \"expected_total_pre\",\n",
    "    \"pace_sum\",\n",
    "    \"eFG_differential\",\n",
    "]\n",
    "\n",
    "for col in score_features:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "y_home = df[\"home_teamScore\"]\n",
    "y_away = df[\"away_teamScore\"]\n",
    "\n",
    "X = df[score_features]\n",
    "\n",
    "X_train, X_test, yh_train, yh_test = train_test_split(X, y_home, test_size=0.2, random_state=42)\n",
    "_, _, ya_train, ya_test = train_test_split(X, y_away, test_size=0.2, random_state=42)\n",
    "\n",
    "model_home = XGBRegressor(\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_away = XGBRegressor(\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_home.fit(X_train, yh_train)\n",
    "model_away.fit(X_train, ya_train)\n",
    "\n",
    "df[\"pred_home_points\"] = model_home.predict(X)\n",
    "df[\"pred_away_points\"] = model_away.predict(X)\n",
    "\n",
    "# Ensure means are positive\n",
    "df[\"pred_home_points\"] = np.clip(df[\"pred_home_points\"], 1, None)\n",
    "df[\"pred_away_points\"] = np.clip(df[\"pred_away_points\"], 1, None)\n",
    "\n",
    "df[\"skellam_ot_prob\"] = skellam.pmf(\n",
    "    0,\n",
    "    mu1=df[\"pred_home_points\"],\n",
    "    mu2=df[\"pred_away_points\"]\n",
    ")\n",
    "\n",
    "print(df[[\"gameId\", \"skellam_ot_prob\"]].head())\n",
    "\n",
    "# Example probability\n",
    "sample_prob = df.iloc[-1][\"skellam_ot_prob\"]\n",
    "print(f\"\\nPredicted Skellam OT probability: {sample_prob * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8693de4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.dirname(os.getcwd())\n",
    "models_dir = os.path.join(base_dir, \"models\")\n",
    "scalers_dir = os.path.join(base_dir, 'scalers')\n",
    "\n",
    "MODEL_PATH = os.path.join(models_dir, \"overtime_model_gb.pkl\")\n",
    "SCALER_PATH = os.path.join(scalers_dir, \"overtime_scaler.pkl\")\n",
    "\n",
    "joblib.dump(model, MODEL_PATH)\n",
    "joblib.dump(scaler, SCALER_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
